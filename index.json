[{"authors":["admin"],"categories":null,"content":"Lorenzo Perini is a research scientist in the Central Applied Science (CAS) team at Meta focusing on probabilistic machine learning. He earned his BSc in Mathematics from the University of Florence in 2017, and his MSc in Mathematical Engineering from Politecnico di Torino in 2019, where he specialized in data statistics and network optimization. His Master\u0026rsquo;s thesis, conducted in collaboration with Tierra S.p.A., explored predictive maintenance using Hidden Markov Models and Autoencoders.\nIn 2019, Lorenzo began his PhD in the DTAI Lab at KU Leuven under Prof. Dr. Jesse Davis, focusing on uncertainty quantification and anomaly detection. His work has been recognized with several fellowships, including a PhD fellowship from the Research Foundation – Flanders (FWO) and the Scientific Prize Gustave Boël-Sofina Fellowship for talented researchers for a long stay abroad. During his PhD, he was a visiting researcher at the University of Helsinki and completed an internship at Bosch Center for Artificial Intelligence (BCAI).\nLorenzo has published papers in prestigious conferences such as NeurIPS, ICML, KDD, AAAI, IJCAI, and ECAI. His main research interests include Uncertainty Quantification and Anomaly Detection, often with the introduction of the human-in-the-loop, e.g. via Active Learning and Learning to Reject. In March 2024, he defended his doctoral dissertation titled operational, uncertainty-aware, and reliable anomaly detection.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://lorenzo-perini.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Lorenzo Perini is a research scientist in the Central Applied Science (CAS) team at Meta focusing on probabilistic machine learning. He earned his BSc in Mathematics from the University of Florence in 2017, and his MSc in Mathematical Engineering from Politecnico di Torino in 2019, where he specialized in data statistics and network optimization. His Master\u0026rsquo;s thesis, conducted in collaboration with Tierra S.p.A., explored predictive maintenance using Hidden Markov Models and Autoencoders.","tags":null,"title":"Lorenzo Perini","type":"authors"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1711636200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711636200,"objectID":"ecde1be079bcf25ea52d646e8364d5fd","permalink":"https://lorenzo-perini.github.io/talk/phdthesis/","publishdate":"2024-04-01T00:00:00Z","relpermalink":"/talk/phdthesis/","section":"talk","summary":"Anomaly detection methods aim to identify examples that do not follow the expected behavior. For various reasons, anomaly detection is typically tackled by using unsupervised approaches that assign real-valued anomaly scores based on various heuristics. For instance, one can assume that anomalies fall in low-density regions and compute the negative log-likelihood as anomaly score. Because anomaly scores are often hard to interpret, practitioners need class labels (i.e., anomaly yes/no) for decision-making. That is, one needs to set a proper decision threshold to flag high-score examples as anomalies. However, finding a threshold requires having access to labeled examples for evaluating the quality of the predicted class labels, which is unfeasible in unsupervised anomaly detection. Moreover, existing literature has focused mainly on measuring the quality of the anomaly scores through ranking-based metrics (e.g., AUROC), which largely ignores the problem of how to derive class predictions. Here, we fill this gap by proposing three novel approaches to transform scores into class predictions. Given a detector’s class predictions, a natural question is: how likely does a prediction change when learning a detector on training data that is subject to slight perturbation? Because unsupervised detectors cannot refine the decision boundary by leveraging labeled examples, they tend to have high uncertainty in predictions. That is, slight changes in the training set often would yield a different decision boundary which, in turn, would flip some test examples’ class prediction. This uncertainty makes it hard to deploy a detector in real-world applications as it deteriorates the practitioner’s trust in its crucial predictions. Because existing literature largely ignores this problem, we fill this gap by proposing an unsupervised approach to quantify a detector’s uncertainty in predictions. While quantifying uncertainty is essential, practitioners also need a reliable way to assess whether they can trust a detector’s prediction. That is, one needs to answer the question: is the detector’s uncertainty low enough to rely on its prediction? This falls into the field of Learning with Rejection, where the model is allowed to abstain (i.e., defer the decision, or “reject” it) when its uncertainty is too high, such that practitioners can trust its output whenever it makes a prediction. Traditionally, learning with rejection approaches rely on evaluating the risk (or, equivalently, the cost) of making mispredictions to design the rejection mechanism, which requires labeled examples. Because no unsupervised method for rejection exists, we fill this gap and propose the first unsupervised anomaly detection algorithm with rejection.","tags":["Anomaly Detection","PU Learning","Uncertainty Quantification","Bayesian Learning","Transfer Learning","Active Learning","Learning to Reject","Unsupervised Learning"],"title":"Operational, Uncertainty-Aware, and Reliable Anomaly Detection","type":"talk"},{"authors":[" Luca Stradiotti"," Lorenzo Perini"," Jesse Davis"],"categories":null,"content":"Summary about Combining Active Learning and Learning to Reject for Anomaly Detection.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"bed921fb4a4c151bf028503cf20b0322","permalink":"https://lorenzo-perini.github.io/publication/stradiotti2024combining/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/stradiotti2024combining/","section":"publication","summary":"Summary about Combining Active Learning and Learning to Reject for Anomaly Detection.","tags":null,"title":"Combining Active Learning and Learning to Reject for Anomaly Detection","type":"publication"},{"authors":[" Andrea Pugnana"," Lorenzo Perini"," Jesse Davis"," Salvatore Ruggieri"],"categories":null,"content":"Summary about Deep neural network benchmarks for selective classification.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"9aa7c74a6fa972e48ebf5e901092254c","permalink":"https://lorenzo-perini.github.io/publication/pugnana2024deep/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/pugnana2024deep/","section":"publication","summary":"Summary about Deep neural network benchmarks for selective classification.","tags":null,"title":"Deep neural network benchmarks for selective classification","type":"publication"},{"authors":[" Kilian Hendrickx"," Lorenzo Perini"," Dries Van der Plas"," Wannes Meert"," Jesse Davis"],"categories":null,"content":"Summary about Machine learning with a reject option: A survey.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"50b5af0aee0055059b4d0451c0a20bf1","permalink":"https://lorenzo-perini.github.io/publication/hendrickx2024machine/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/hendrickx2024machine/","section":"publication","summary":"Summary about Machine learning with a reject option: A survey.","tags":null,"title":"Machine learning with a reject option: A survey","type":"publication"},{"authors":[" Luca Stradiotti"," Lorenzo Perini"," Jesse Davis"],"categories":null,"content":"Summary about Semi-Supervised Isolation Forest for Anomaly Detection.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"55b384c83874f69a4f675371601fc443","permalink":"https://lorenzo-perini.github.io/publication/stradiotti2024semi/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/stradiotti2024semi/","section":"publication","summary":"Summary about Semi-Supervised Isolation Forest for Anomaly Detection.","tags":null,"title":"Semi-Supervised Isolation Forest for Anomaly Detection","type":"publication"},{"authors":[" Lorenzo Perini"," Maja Rudolph"," Sabrina Schmedding"," Chen Qiu"],"categories":null,"content":"Summary about Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"2744051c2d3fdbd8cc57cf2accde97bd","permalink":"https://lorenzo-perini.github.io/publication/perini2024uncertainty/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/perini2024uncertainty/","section":"publication","summary":"Summary about Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior.","tags":null,"title":"Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior","type":"publication"},{"authors":[" Lorenzo Perini"," Jesse Davis"],"categories":null,"content":"Summary about Unsupervised anomaly detection with rejection.\n","date":1704063600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704063600,"objectID":"2a3420d8ebb2ea457b1630b291db4bfc","permalink":"https://lorenzo-perini.github.io/publication/perini2024unsupervised/","publishdate":"2024-01-01T00:00:00+01:00","relpermalink":"/publication/perini2024unsupervised/","section":"publication","summary":"Summary about Unsupervised anomaly detection with rejection.","tags":null,"title":"Unsupervised anomaly detection with rejection","type":"publication"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1702575900,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702575900,"objectID":"bbc866d355e2a10af4690e5a7ff5fade","permalink":"https://lorenzo-perini.github.io/talk/neurips23/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/talk/neurips23/","section":"talk","summary":"Anomaly detection aims at detecting unexpected behaviours in the data. Because anomaly detection is usually an unsupervised task, traditional anomaly detectors learn a decision boundary by employing heuristics based on intuitions, which are hard to verify in practice. This introduces some uncertainty, especially close to the decision boundary, that may reduce the user trust in the detector's predictions. A way to combat this is by allowing the detector to reject examples with high uncertainty (Learning to Reject). This requires employing a confidence metric that captures the distance to the decision boundary and setting a rejection threshold to reject low-confidence predictions. However, selecting a proper metric and setting the rejection threshold without labels are challenging tasks. In this paper, we solve these challenges by setting a constant rejection threshold on the stability metric computed by ExCeeD. Our insight relies on a theoretical analysis of such a metric. Moreover, setting a constant threshold results in strong guarantees: we estimate the test rejection rate, and derive a theoretical upper bound for both the rejection rate and the expected prediction cost. Experimentally, we show that our method outperforms some metric-based methods.","tags":["Anomaly Detection","Learning to Reject","Unsupervised Learning"],"title":"Unsupervised Anomaly Detection with Rejection @ NeurIPS23","type":"talk"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1691493600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691493600,"objectID":"362bf094ccafc9c84356298525961973","permalink":"https://lorenzo-perini.github.io/talk/kdd23/","publishdate":"2023-08-05T00:00:00Z","relpermalink":"/talk/kdd23/","section":"talk","summary":"In the multi-instance learning (MIL) setting instances are grouped together into bags. Labels are provided only for the bags and not on the level of individual instances. A positive bag label means that at least one instance inside the bag is positive, while a negative bag label restricts all the instances in the bag to be negative. MIL data naturally arises in many contexts, such as anomaly detection, where labels are rare and costly, and one often ends up annotating the label for sets of instances. Moreover, in many real-world anomaly detection problems, only positive labels are collected because they usually represent critical events. Such a setting, where only positive labels are provided along with unlabeled data, is called Positive and Unlabeled (PU) learning. Despite being useful for several use cases, there is no work dedicated to learning from positive and unlabeled data in a multi-instance setting for anomaly detection. Therefore, we propose the first method that learns from PU bags in anomaly detection. Our method uses an autoencoder as an underlying anomaly detector. We alter the autoencoder’s objective function and propose a new loss that allows it to learn from positive and unlabeled bags of instances. We theoretically analyze this method. Experimentally, we evaluate our method on 30 datasets and show that it performs better than multiple baselines adapted to work in our setting.","tags":["Multi-Instance Learning","PU Learning","Anomaly Detection"],"title":"Learning from Positive and Unlabeled Multi-Instance Bags in Anomaly Detection @ KDD23","type":"talk"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1690390800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690390800,"objectID":"49fac8c0a88f4cb911da9aa6f9bfc7e9","permalink":"https://lorenzo-perini.github.io/talk/icml23/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/talk/icml23/","section":"talk","summary":"Anomaly detection methods identify examples that do not follow the expected behaviour, typically in an unsupervised fashion, by assigning real-valued anomaly scores to the examples based on various heuristics. These scores need to be transformed into actual predictions by thresholding so that the proportion of examples marked as anomalies equals the expected proportion of anomalies, called contamination factor. Unfortunately, there are no good methods for estimating the contamination factor itself. We address this need from a Bayesian perspective, introducing a method for estimating the posterior distribution of the contamination factor for a given unlabeled dataset. We leverage several anomaly detectors to capture the basic notion of anomalousness and estimate the contamination using a specific mixture formulation. Empirically on 22 datasets, we show that the estimated distribution is well-calibrated and that setting the threshold using the posterior mean improves the detectors’ performance over several alternative methods.","tags":["Anomaly Detection","Bayesian Methods","Unsupervised Learning"],"title":"Estimating the Contamination Factor’s Distribution in Unsupervised Anomaly Detection @ ICML23","type":"talk"},{"authors":[],"categories":null,"content":"","date":1676291400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676291400,"objectID":"d3f6c7909db7745f1037e0cb11e5a977","permalink":"https://lorenzo-perini.github.io/talk/aaai/","publishdate":"2023-02-13T13:30:00+01:00","relpermalink":"/talk/aaai/","section":"talk","summary":"Anomaly detection attempts at finding examples that deviate from the expected behaviour. Usually, anomaly detection is tackled from an unsupervised perspective because anomalous labels are rare and difficult to acquire. However, the lack of labels makes the anomaly detector have high uncertainty in some regions, which usually results in poor predictive performance or low user trust in the predictions. One can reduce such uncertainty by collecting specific labels using Active Learning (AL), which targets examples close to the detector's decision boundary. Alternatively, one can increase the user trust by allowing the detector to abstain from making highly uncertain predictions, which is called Learning to Reject (LR). One way to do this is by thresholding the detector's uncertainty based on where its performance is low, which requires labels to be evaluated. Although both AL and LR need labels, they work with different types of labels: AL seeks strategic labels, which are evidently biased, while LR requires i.i.d. labels to evaluate the detector's performance and set the rejection threshold. Because one usually has a unique label budget, deciding how to optimally allocate it is challenging. In this paper, we propose a mixed strategy that, given a budget of labels, decides in multiple rounds whether to use the budget to collect AL labels or LR labels. The strategy is based on a reward function that measures the expected gain when allocating the budget to either side. We evaluate our strategy on 18 benchmark datasets and compare it to some baselines.","tags":["Uncertainty Quantification","Anomaly Detection","Active Learning","Learning to Reject"],"title":"How to Allocate your Label Budget? Choosing between Active Learning and Learning to Reject in Anomaly Detection @ AAAI23","type":"talk"},{"authors":[],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"2149f0c88b157e0f8ec0707bfa3810de","permalink":"https://lorenzo-perini.github.io/thesis/5year/second/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/thesis/5year/second/","section":"thesis","summary":"This thesis explores a novel active learning strategy for deep semi-supervised models with rejection, addressing classification tasks where mispredictions carry severe consequences and labeled data are scarce. By integrating active learning, semi-supervised learning, and learning with rejection, the proposed approach enables models to reject uncertain predictions and learn effectively from unlabeled data. The primary challenge lies in adapting active learning to models with rejection, as traditional strategies focus solely on improving predictive accuracy without accounting for the need to identify rejectable instances. To address this, the proposed strategy dynamically balances two complementary approaches. The first employs a cost-based framework to select data points likely to reduce the overall cost of mispredictions and rejections. The second approach mitigates sampling bias to enhance the robustness of the active learning process. Extensive experiments on five real-world datasets demonstrate the strategy’s effectiveness, achieving better and more robust performance compared to uncertainty sampling and random sampling baselines across various scenarios. These results underscore the potential of the proposed strategy to improve the efficiency and reliability of deep semi-supervised models with rejection.","tags":[],"title":"Better be cautious when asking hard questions! Developing an active learning strategy for semi-supervised models with rejection","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"2d1524173b6de84da026d42a261c152b","permalink":"https://lorenzo-perini.github.io/thesis/5year/third/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/thesis/5year/third/","section":"thesis","summary":"This thesis investigates a novel approach for data acquisition in anomaly detection, a critical field in machine learning focused on identifying unusual patterns in datasets. The goal is to develop a semi-supervised anomaly detection model that learns from pairwise ranked data, thereby simplifying the expert’s labeling process. By combining semi-supervised anomaly detection with supervised learning techniques from the learning-to-rank domain, the proposed method, SSPS, is tested on various benchmark datasets to evaluate its predictive performance. The results demonstrate that SSPS competes with state-of-the-art learning-to-rank algorithms applied to anomaly detection tasks, outperforming them on datasets where supervised learning struggles. This research suggests that ranking-based learning could offer a promising alternative for anomaly detection, particularly in scenarios where normal data points can be ranked relative to each other, such as credit card fraud detection and machine failure. The findings lay the groundwork for future research in semi-supervised pairwise anomaly detection as pairwise anomaly datasets become available.","tags":[],"title":"It may not be wrong but is definitely more anomalous than the others! Anomaly Detection with User Feedback Ranking","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"46fedc928ae6b2e933e22c3101b9b608","permalink":"https://lorenzo-perini.github.io/thesis/5year/first/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/thesis/5year/first/","section":"thesis","summary":"Anomaly detection aims to identify unexpected events, known as anomalies, that deviate from normal behavior and often represent critical occurrences. While typically addressed in an unsupervised manner, anomaly detection can benefit from weak supervision to reduce labeling costs. Multi-Instance Learning (MIL) provides a framework for weakly supervised anomaly detection by organizing data into labeled sets (bags) of instances, where a bag is anomalous if at least one instance is anomalous. In scenarios where labels are expensive, Active Learning strategies can optimize instance selection for labeling. However, standard strategies may be suboptimal in MIL settings due to varying distributions across bags. To address this, we propose the Aligning Multi-Instance Bandits (AMIB) method, which aligns normal instances across bags to follow a common distribution. AMIB combines a Multi-Armed Bandits approach for bag selection with Uncertainty Sampling for instance querying. Experimental results indicate that AMIB competes with standard Active Learning strategies at the instance level, particularly when anomalous instances overlap with normal ones across bags. However, at the bag level, AMIB demonstrates poor performance, yielding results comparable to a random classifier. These findings highlight AMIB's potential and limitations, offering insights for further research in MIL-based Active Learning for anomaly detection.","tags":[],"title":"What do slot machines have in common with Active Learning? Finding the high-reward instances in Multi-Instance Learning","type":"thesis"},{"authors":[" Laurens Devos"," Lorenzo Perini"," Wannes Meert"," Jesse Davis"],"categories":null,"content":"Summary about Detecting evasion attacks in deployed tree ensembles.\n","date":1672527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672527600,"objectID":"96f295dd549a023a81cae54d1bd17994","permalink":"https://lorenzo-perini.github.io/publication/devos2023detecting/","publishdate":"2023-01-01T00:00:00+01:00","relpermalink":"/publication/devos2023detecting/","section":"publication","summary":"Summary about Detecting evasion attacks in deployed tree ensembles.","tags":null,"title":"Detecting evasion attacks in deployed tree ensembles","type":"publication"},{"authors":[" Lorenzo Perini"," Paul-Christian Bürkner"," Arto Klami"],"categories":null,"content":"Summary about Estimating the contamination factor’s distribution in unsupervised anomaly detection.\n","date":1672527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672527600,"objectID":"ed38a503869e928ce5d5bdbd946ce71e","permalink":"https://lorenzo-perini.github.io/publication/perini2023estimating/","publishdate":"2023-01-01T00:00:00+01:00","relpermalink":"/publication/perini2023estimating/","section":"publication","summary":"Summary about Estimating the contamination factor’s distribution in unsupervised anomaly detection.","tags":null,"title":"Estimating the contamination factor’s distribution in unsupervised anomaly detection","type":"publication"},{"authors":[" Lorenzo Perini"," Daniele Giannuzzi"," Jesse Davis"],"categories":null,"content":"Summary about How to allocate your label budget? choosing between active learning and learning to reject in anomaly detection.\n","date":1672527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672527600,"objectID":"76901c288814e1d4339220b9b59850d9","permalink":"https://lorenzo-perini.github.io/publication/perini2023allocate/","publishdate":"2023-01-01T00:00:00+01:00","relpermalink":"/publication/perini2023allocate/","section":"publication","summary":"Summary about How to allocate your label budget? choosing between active learning and learning to reject in anomaly detection.","tags":null,"title":"How to allocate your label budget? choosing between active learning and learning to reject in anomaly detection","type":"publication"},{"authors":[" Lorenzo Perini"," Vincent Vercruyssen"," Jesse Davis"],"categories":null,"content":"Summary about Learning from positive and unlabeled multi-instance bags in anomaly detection.\n","date":1672527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672527600,"objectID":"4fb4fa9d4afca673e596536eca2a88d4","permalink":"https://lorenzo-perini.github.io/publication/perini2023learning/","publishdate":"2023-01-01T00:00:00+01:00","relpermalink":"/publication/perini2023learning/","section":"publication","summary":"Summary about Learning from positive and unlabeled multi-instance bags in anomaly detection.","tags":null,"title":"Learning from positive and unlabeled multi-instance bags in anomaly detection","type":"publication"},{"authors":[" Timo Martens"," Lorenzo Perini"," Jesse Davis"],"categories":null,"content":"Summary about Semi-supervised learning from active noisy soft labels for anomaly detection.\n","date":1672527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672527600,"objectID":"4789277a7bc0a7cae1fd0330da0df155","permalink":"https://lorenzo-perini.github.io/publication/martens2023semi/","publishdate":"2023-01-01T00:00:00+01:00","relpermalink":"/publication/martens2023semi/","section":"publication","summary":"Summary about Semi-supervised learning from active noisy soft labels for anomaly detection.","tags":null,"title":"Semi-supervised learning from active noisy soft labels for anomaly detection","type":"publication"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1645812000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645812000,"objectID":"84954541c495de5db77f83eae22817b4","permalink":"https://lorenzo-perini.github.io/talk/aaai22/","publishdate":"2022-02-15T11:53:37+02:00","relpermalink":"/talk/aaai22/","section":"talk","summary":"Anomaly detection attempts to find examples in a dataset that do not conform to the expected behavior. Algorithms for this task assign an anomaly score to each example representing its degree of anomalousness. Setting a threshold on the anomaly scores enables converting these scores into a discrete prediction for each example. Setting an appropriate threshold is challenging in practice since anomaly detection is often treated as an unsupervised problem. A common approach is to set the threshold based on the dataset’s contamination factor, i.e., the proportion of anomalous examples in the data. While the contamination factor may be known based on domain knowledge, it is often necessary to estimate it by labeling data. However, many anomaly detection problems involve monitoring multiple related, yet slightly different entities (e.g., a fleet of machines). Then, estimating the contamination factor for each dataset separately by labeling data would be extremely time-consuming. Therefore, this paper introduces a method for transferring the known contamination factor from one dataset (the source domain) to a related dataset where it is unknown (the target domain). Our approach does not require labeled target data and is based on modeling the shape of the distribution of the anomaly scores in both domains. We theoretically analyze how our method behaves when the (biased) target domain anomaly score distribution converges to its true one. Empirically, our method outperforms several baselines on real-world datasets.","tags":["Transfer Learning","Unsupervised Learning","Anomaly Detection"],"title":"Transferring the Contamination Factor between Anomaly Detection Domains by Shape Similarity @ AAAI22","type":"talk"},{"authors":[],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"51d909a1826efd5c38b31410becffbc0","permalink":"https://lorenzo-perini.github.io/thesis/4year/second/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/thesis/4year/second/","section":"thesis","summary":"Anomaly detection models often rely on anomaly scores to make predictions, but these scores are difficult to interpret and compare, making it challenging to derive confidence in predictions. To address this, anomaly scores can be transformed into calibrated probabilities through a calibration map. While traditional calibration methods require labeled data, this reliance conflicts with the largely unsupervised nature of anomaly detection. This work introduces a novel semi-supervised calibration method that bridges this gap by combining two approaches. The first approach uses statistical insights to define the likely region of a good calibration map, minimizing the area where accurate predictions may reside. The second approach augments the limited labeled data by generating additional pseudo-labels for unlabeled items, enabling the application of supervised calibration techniques. The final method integrates these approaches, adjusting the calibration map from the second approach to fit within the boundaries set by the first. Evaluations on 15 anomaly score sets from various models and benchmark datasets reveal that while the proposed method does not consistently outperform existing calibration methods, it provides valuable insights into semi-supervised calibration. These approaches, individually or combined, form a solid foundation for advancing the calibration of anomaly scores in future research.","tags":[],"title":"It is likely not to be so likely! Semi-supervised calibration of anomaly scores","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"4dadbcfa2174f748c8799cd9ac2edc51","permalink":"https://lorenzo-perini.github.io/thesis/4year/first/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/thesis/4year/first/","section":"thesis","summary":"Anomaly detection involves identifying instances in data that deviate from expected patterns, typically by assigning anomaly scores to measure deviation. These scores, combined with thresholds, determine labels. However, the diverse scoring approaches used in current algorithms can hinder interpretability and reduce user trust in critical decisions. ExCeeD, the current state-of-the-art method for quantifying confidence in anomaly detection, has notable limitations: it depends on the true proportion of anomalies in the dataset and uses a discrete mapping of anomaly scores to confidence intervals. This thesis introduces the Lismont method, a novel approach to quantify confidence in anomaly detection. Unlike ExCeeD, the Lismont method calculates continuous confidence values without relying on the dataset’s true anomaly proportion. Additionally, we propose a new metric to evaluate the continuity of confidence methods. Experimental results demonstrate that the Lismont method improves performance over ExCeeD across various scenarios, offering enhanced confidence quantification and greater interpretability in anomaly detection tasks.","tags":[],"title":"This is critical and a lot is at stake. How can I trust the model? Quantifying the model uncertainty in anomaly detection","type":"thesis"},{"authors":[" Vincent Vercruyssen"," Lorenzo Perini"," Wannes Meert"," Jesse Davis"],"categories":null,"content":"Summary about Multi-domain active learning for semi-supervised anomaly detection.\n","date":1640991600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640991600,"objectID":"338257459614dc5dff8be8348eedd21a","permalink":"https://lorenzo-perini.github.io/publication/vercruyssen2022multi/","publishdate":"2022-01-01T00:00:00+01:00","relpermalink":"/publication/vercruyssen2022multi/","section":"publication","summary":"Summary about Multi-domain active learning for semi-supervised anomaly detection.","tags":null,"title":"Multi-domain active learning for semi-supervised anomaly detection","type":"publication"},{"authors":[" Lorenzo Perini"," Vincent Vercruyssen"," Jesse Davis"],"categories":null,"content":"Summary about Transferring the contamination factor between anomaly detection domains by shape similarity.\n","date":1640991600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640991600,"objectID":"16ad5e0e8e8df9245e1dc9e203f61d6b","permalink":"https://lorenzo-perini.github.io/publication/perini2022transferring/","publishdate":"2022-01-01T00:00:00+01:00","relpermalink":"/publication/perini2022transferring/","section":"publication","summary":"Summary about Transferring the contamination factor between anomaly detection domains by shape similarity.","tags":null,"title":"Transferring the contamination factor between anomaly detection domains by shape similarity","type":"publication"},{"authors":[],"categories":null,"content":"","date":1614616200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614616200,"objectID":"0f813efe7e3199da42662f1905bb4034","permalink":"https://lorenzo-perini.github.io/talk/polito/","publishdate":"2021-03-01T17:30:00+01:00","relpermalink":"/talk/polito/","section":"talk","summary":"","tags":["Uncertainty Quantification","Anomaly Detection"],"title":"Quantifying the Confidence of Anomaly Detectors in Their Example-Wise Predictions @ Polito","type":"talk"},{"authors":[],"categories":[],"content":"","date":1612998000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612998000,"objectID":"373ec5f4c4db1b82fe3f13e4d22704d2","permalink":"https://lorenzo-perini.github.io/award/fwo_fellowship/","publishdate":"2021-02-11T00:00:00+01:00","relpermalink":"/award/fwo_fellowship/","section":"award","summary":"PhD grant for the research project ''Measuring and Exploiting the Uncertainty in Anomaly Detection''.","tags":[],"title":"PhD Fellowship fundamental research (FWO)","type":"award"},{"authors":[],"categories":[],"content":"","date":1612998000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612998000,"objectID":"f451c30dca3854993457fbb7574ace33","permalink":"https://lorenzo-perini.github.io/award/sb_fellowship/","publishdate":"2021-02-11T00:00:00+01:00","relpermalink":"/award/sb_fellowship/","section":"award","summary":"F.R.S.-FNRS \u0026 FWO grant for talented PhD students for a long research stay abroad.","tags":[],"title":"Scientific prize Gustave Boël-Sofina Fellowship","type":"award"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1610647800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610647800,"objectID":"0e2f64af4d7bfd74e1ad78faf54880b3","permalink":"https://lorenzo-perini.github.io/talk/ijcai20/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/talk/ijcai20/","section":"talk","summary":"Estimating the proportion of positive examples (i.e., the class prior) from positive and unlabeled (PU) data is an important task that facilitates learning a classifier from such data. In this paper, we explore how to tackle this problem when the observed labels were acquired via active learning. This introduces the challenge that the observed labels were not selected completely at random, which is the primary assumption underpinning existing approaches to estimating the class prior from PU data. We analyze this new setting and design an algorithm that is able to estimate the class prior for a given active learning strategy. Empirically, we show that our approach accurately recovers the true class prior on a benchmark of anomaly detection datasets and that it does so more accurately than existing methods.","tags":["PU Learning","Active Learning","Anomaly Detection"],"title":"Class Prior Estimation in Active Positive and Unlabeled Learning @ IJCAI20","type":"talk"},{"authors":[],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"f36bbe2cec6cb0d8ea86bbc69b349c2a","permalink":"https://lorenzo-perini.github.io/thesis/3year/second/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/thesis/3year/second/","section":"thesis","summary":"Detecting abnormal behaviors in real-world applications is critical for preventing dangerous situations. While anomaly detection has traditionally been treated as an unsupervised learning task due to the scarcity and cost of labeled data, the availability of limited labels has spurred the development of semi-supervised models that significantly enhance performance. Among these, tree-based models are a promising but underexplored approach due to the challenge of integrating labeled and unlabeled data during tree construction. This work introduces a novel semi-supervised tree-based model that leverages both labeled and unlabeled data to effectively partition the feature space, distinguishing normal samples from anomalies. The proposed method is evaluated on multiple benchmark datasets and compared against state-of-the-art algorithms. Results demonstrate that the model consistently outperforms unsupervised and semi-supervised baselines, highlighting its potential for robust anomaly detection in semi-supervised scenarios.","tags":[],"title":"Adaptive semi-supervised anomaly detection with any unsupervised prior","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"0b09fd5d1350d3aa76076bcd1d473560","permalink":"https://lorenzo-perini.github.io/thesis/3year/third/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/thesis/3year/third/","section":"thesis","summary":"Anomaly detection is a machine learning task in which the goal is to detect the outliers in a given data set. In real-life applications, one usually has a label budget because collecting labels can be costly. This is where semi-supervised anomaly detection models come in. They are able to learn from a limited labeled data set and a larger set of unlabeled data. However, they usually assume only correct labels, but labeling data can be a very challenging task. Due to the small set of labeled data, noisy labels can have a detrimental effect on the model's accuracy. We introduce a new setting in which the human annotator is asked to provide a confidence score along with her labels. Subsequently, we propose a novel semi-supervised anomaly detection model that incorporates these confidence scores to become more robust against noisy labels. By simulating a human annotator, we can compare our model against the state of the art on multiple benchmark data sets. We find empirical evidence for the robustness of our model, but have to conclude that it lacks other desired properties such as, e.g. the speed at which it learns.","tags":[],"title":"Practice makes perfect? Detecting anomalies by learning from imperfect user’s feedback","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4c365661862aebbc874ee0ade697c817","permalink":"https://lorenzo-perini.github.io/thesis/3year/first/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/thesis/3year/first/","section":"thesis","summary":"The challenge of abstaining from uncertain predictions has gained significant attention in recent years. While the introduction of a reject option has been explored in supervised learning, its application in anomaly detection—a domain with limited labels and high costs for misclassification—remains unexplored. This work proposes a novel framework enabling anomaly detectors to abstain from uncertain predictions in both unsupervised and semi-supervised scenarios. The approach leverages a dependent rejector based on model confidence, making it adaptable to various anomaly detection methods. In the unsupervised setting, a natural threshold is used for rejection, whereas in the semi-supervised case, the threshold is optimized using labeled data to minimize overall costs. Additionally, cosine distance is employed to measure the reward of using labels for either Active Learning or Learning to Reject, balancing their trade-offs. Experiments on a benchmark of nine anomaly detection datasets demonstrate the framework’s effectiveness, showing significant improvements in rejecting high-cost misclassifications. The proposed framework, integrating rejection, outperforms standard Active Learning approaches in both unsupervised and semi-supervised settings, reducing risk and enhancing reliability.","tags":[],"title":"To ask or to abstain, what is the best strategy? Finding the best trade-off between Active Learning and Learning to Reject","type":"thesis"},{"authors":[" Jonas Soenen"," Elia Van Wolputte"," Lorenzo Perini"," Vincent Vercruyssen"," Wannes Meert"," Jesse Davis"," Hendrik Blockeel"],"categories":null,"content":"Summary about The effect of hyperparameter tuning on the comparative evaluation of unsupervised anomaly detection methods.\n","date":1609455600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609455600,"objectID":"dc75f8970dbed47d6491086b93eeed83","permalink":"https://lorenzo-perini.github.io/publication/soenen2021effect/","publishdate":"2021-01-01T00:00:00+01:00","relpermalink":"/publication/soenen2021effect/","section":"publication","summary":"Summary about The effect of hyperparameter tuning on the comparative evaluation of unsupervised anomaly detection methods.","tags":null,"title":"The effect of hyperparameter tuning on the comparative evaluation of unsupervised anomaly detection methods","type":"publication"},{"authors":null,"categories":[],"content":"","date":1600255800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600255800,"objectID":"21df1adebf913c8a02313c9358cf1d91","permalink":"https://lorenzo-perini.github.io/talk/edml20/","publishdate":"2020-08-21T12:35:55+02:00","relpermalink":"/talk/edml20/","section":"talk","summary":"Anomaly detection attempts to learn models from data that can detect anomalous examples in the data. However, naturally occurring variations in the data impact the model that is learned and thus which examples it will predict to be anomalies. Ideally, an anomaly detection method should be robust to such small changes in the data. Hence, this paper introduces a ranking stability measure that quantifies the robustness of any anomaly detector's predictions by looking at how consistently it ranks examples in terms of their anomalousness. Our experiments investigate the performance of this stability measure under different data perturbation schemes. In addition, they show how the stability measure can complement traditional anomaly detection performance measures, such as area under the ROC curve or average precision, to quantify the behaviour of different anomaly detection methods.","tags":["Ranking Stability","Anomaly Detection","Classifier Trust"],"title":"A Ranking Stability Measure for Quantifying the Robustness of Anomaly Detection Methods @ ECML20","type":"talk"},{"authors":["Lorenzo Perini"],"categories":[],"content":"","date":1600254000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600254000,"objectID":"5e3bed587aad0b1c42ad9000eeb1ce3e","permalink":"https://lorenzo-perini.github.io/talk/ecml20/","publishdate":"2020-08-21T12:25:53+02:00","relpermalink":"/talk/ecml20/","section":"talk","summary":"Anomaly detection focuses on identifying examples in the data that somehow deviate from what is expected or typical. Algorithms for this task usually assign a score to each example that represents how anomalous the example is. Then, a threshold on the scores turns them into concrete predictions. However, each algorithm uses a different approach to assign the scores, which makes them difficult to interpret and can quickly erode a user's trust in the predictions. This paper introduces an approach for assessing the reliability of any anomaly detector's example-wise predictions. To do so, we propose a Bayesian approach for converting anomaly scores to probability estimates. This enables the anomaly detector to assign a confidence score to each prediction which captures its uncertainty in that prediction. We theoretically analyze the convergence behaviour of our confidence estimate. Empirically, we demonstrate the effectiveness of the framework in quantifying a detector's confidence in its predictions on a large benchmark of datasets.","tags":["Anomaly Detection","Interpretability","Confidence Scores"],"title":"Quantifying the Confidence of Anomaly Detectors in Their Example-Wise Predictions @ ECML20","type":"talk"},{"authors":[],"categories":[],"content":"","date":1598256914,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598256914,"objectID":"d5ef38474751715cc3dea6d152772ce0","permalink":"https://lorenzo-perini.github.io/course/pulearning/","publishdate":"2020-08-24T10:15:14+02:00","relpermalink":"/course/pulearning/","section":"course","summary":"2020/2021, 2021/2022","tags":[],"title":"Capita Selecta Computer Science: PU Learning","type":"course"},{"authors":[],"categories":[],"content":"","date":1598256914,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598256914,"objectID":"bdba931ff2a5f4a110fe4bbb0d893e9f","permalink":"https://lorenzo-perini.github.io/course/datamining/","publishdate":"2020-08-24T10:15:14+02:00","relpermalink":"/course/datamining/","section":"course","summary":"2019/2020, 2020/2021, 2022/2023","tags":[],"title":"Data Mining","type":"course"},{"authors":[],"categories":[],"content":"","date":1598256676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598256676,"objectID":"498d13916311804fdf6ebcf150c6f020","permalink":"https://lorenzo-perini.github.io/award/ecmlpkdd20/","publishdate":"2020-08-24T10:11:16+02:00","relpermalink":"/award/ecmlpkdd20/","section":"award","summary":"Multiple nominations by the conference session chairs as particularly engaging speaker.","tags":[],"title":"Overall ECML-PKDD Engagement Award 2020","type":"award"},{"authors":[],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e654b6c3183702c343954e9df7cce8b7","permalink":"https://lorenzo-perini.github.io/thesis/2year/first/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/thesis/2year/first/","section":"thesis","summary":"Anomaly detection identifies patterns in datasets that deviate from expected behavior, often indicating issues such as fraud, accidents, or intrusions. Due to the size of modern datasets, manual inspection is impractical, necessitating automated methods. This thesis explores anomaly detection using active learning, where a human expert provides annotations for selected data points. Existing methods assume experts can always assign correct labels, but this is unrealistic in practice. We propose a weaker assumption, allowing experts to express uncertainty when unsure about a label, reducing reliance on omniscient annotations. Our approach avoids overly difficult queries by estimating their difficulty and incorporating this estimate into the querying process alongside model uncertainty. Through experiments, we evaluate methods to estimate expert uncertainty, optimize query strategies, and minimize unnecessary queries. To address the lack of datasets with expert uncertainty, we modeled uncertainty on existing anomaly datasets, enabling an evaluation of the proposed framework.","tags":[],"title":"Do you know the answer? Taking into account the user uncertainty in active learning","type":"thesis"},{"authors":[],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"fa67618809b1f7e5f33abdbafc04fb70","permalink":"https://lorenzo-perini.github.io/thesis/2year/second/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/thesis/2year/second/","section":"thesis","summary":"This thesis investigates the application of active learning in anomaly detection, with a focus on the impact of dataset perturbations on query selection. Specifically, we examine the probability of querying a data point x when the dataset is slightly altered. This probability, termed the reliability measure, distinguishes data points that provide meaningful insights into the underlying data distribution from those queried due to unique dataset-specific characteristics. By estimating this probability, we can refine query selection to align more closely with the true data distribution rather than dataset-specific anomalies. The reliability measure also enhances the calibration and interpretability of informativeness scores used in active learning strategies. In the second part of the thesis, we explore combining active learning strategies by leveraging their reliability measures. This approach integrates the assumptions underlying the input strategies, though we find that combining assumptions does not always produce a superior strategy. The proposed framework provides a new perspective on optimizing active learning in anomaly detection through reliability-informed strategies.","tags":[],"title":"Reliability measure in the Active Learning querying phase","type":"thesis"},{"authors":[" Lorenzo Perini"," Connor Galvin"," Vincent Vercruyssen"],"categories":null,"content":"Summary about A ranking stability measure for quantifying the robustness of anomaly detection methods.\n","date":1577833200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577833200,"objectID":"553d423e1c8cb6588630051729775498","permalink":"https://lorenzo-perini.github.io/publication/perini2020ranking/","publishdate":"2020-01-01T00:00:00+01:00","relpermalink":"/publication/perini2020ranking/","section":"publication","summary":"Summary about A ranking stability measure for quantifying the robustness of anomaly detection methods.","tags":null,"title":"A ranking stability measure for quantifying the robustness of anomaly detection methods","type":"publication"},{"authors":[" Lorenzo Perini"," Vincent Vercruyssen"," Jesse Davis"],"categories":null,"content":"Summary about Class Prior Estimation in Active Positive and Unlabeled Learning..\n","date":1577833200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577833200,"objectID":"a2475d690460286608a3ea65173df636","permalink":"https://lorenzo-perini.github.io/publication/perini2020class/","publishdate":"2020-01-01T00:00:00+01:00","relpermalink":"/publication/perini2020class/","section":"publication","summary":"Summary about Class Prior Estimation in Active Positive and Unlabeled Learning..","tags":null,"title":"Class Prior Estimation in Active Positive and Unlabeled Learning.","type":"publication"},{"authors":[" Lorenzo Perini"," Vincent Vercruyssen"," Jesse Davis"],"categories":null,"content":"Summary about Quantifying the confidence of anomaly detectors in their example-wise predictions.\n","date":1577833200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577833200,"objectID":"6232dd34134039b29f49eba06b365c77","permalink":"https://lorenzo-perini.github.io/publication/perini2020quantifying/","publishdate":"2020-01-01T00:00:00+01:00","relpermalink":"/publication/perini2020quantifying/","section":"publication","summary":"Summary about Quantifying the confidence of anomaly detectors in their example-wise predictions.","tags":null,"title":"Quantifying the confidence of anomaly detectors in their example-wise predictions","type":"publication"},{"authors":[],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d32de50d40e4fd5995af286531e188cb","permalink":"https://lorenzo-perini.github.io/thesis/1year/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/thesis/1year/","section":"thesis","summary":"The idea of stability has applications in many areas of machine learning. However, stability has not yet been applied in context of anomaly detection, where there is need for a metric that quantifies the robustness of anomaly score rankings to changes in training data. We propose such a metric and the methodology used in computing it. We then propose to use an algorithm with the goal of maximizing stability by learning training points that contribute most to high stability. Finally, we apply this stability metric and the proposed contribution update algorithm on several benchmark datasets. This evaluation is used to compare stability on different anomaly detection algorithms, and assess the contribution update algorithm's ability to increase stability.","tags":[],"title":"Designing a Stability Metric for Assessing the Robustness of Anomaly Rankings","type":"thesis"},{"authors":[" Lorenzo Perini"],"categories":null,"content":"Summary about Predictive Maintenance for off-road vehicles based on Hidden Markov Models and Autoencoders for trend Anomaly Detection.\n","date":1546297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546297200,"objectID":"9a07435a7131c9e99e766626070c7a29","permalink":"https://lorenzo-perini.github.io/publication/perini2019predictive/","publishdate":"2019-01-01T00:00:00+01:00","relpermalink":"/publication/perini2019predictive/","section":"publication","summary":"Summary about Predictive Maintenance for off-road vehicles based on Hidden Markov Models and Autoencoders for trend Anomaly Detection.","tags":null,"title":"Predictive Maintenance for off-road vehicles based on Hidden Markov Models and Autoencoders for trend Anomaly Detection","type":"publication"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"256f085db9b42d9be9674b4669f81f40","permalink":"https://lorenzo-perini.github.io/reviewer/aaai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/aaai/","section":"reviewer","summary":"Conference","tags":[],"title":"AAAI Conference on Artificial Intelligence (AAAI-21, AAAI-22)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbba21c7d05c83ac5e4303514dc65875","permalink":"https://lorenzo-perini.github.io/reviewer/kdd/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/kdd/","section":"reviewer","summary":"Conference","tags":[],"title":"ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-21, KDD-23)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6bad1e87e8fced13250c39179ae29bc2","permalink":"https://lorenzo-perini.github.io/reviewer/mlj/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/mlj/","section":"reviewer","summary":"Journal","tags":[],"title":"Editorial Board Member of Machine Learning Journal (MLJ)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5cb30cd5335bb5d05f5ef321ea7b0308","permalink":"https://lorenzo-perini.github.io/reviewer/ecml/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/ecml/","section":"reviewer","summary":"Conference","tags":[],"title":"European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-20, ECML-22)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8b392075b975480f7a4cc2257f031f7e","permalink":"https://lorenzo-perini.github.io/reviewer/aistats/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/aistats/","section":"reviewer","summary":"Conference","tags":[],"title":"International Conference on Artificial Intelligence and Statistics (AISTATS-23)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"af4491e277020e9d3b1708989d41e20d","permalink":"https://lorenzo-perini.github.io/reviewer/jair/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/jair/","section":"reviewer","summary":"","tags":[],"title":"Journal of Artificial Intelligence Research (JAIR)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e73f7dce02f6a8a47993dd53efcde13","permalink":"https://lorenzo-perini.github.io/reviewer/neurips/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/neurips/","section":"reviewer","summary":"Conference","tags":[],"title":"Neural Information Processing Systems (NeurIPS-24)","type":"reviewer"},{"authors":[],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"141c50570e8a05106b89515f08c1c5b6","permalink":"https://lorenzo-perini.github.io/reviewer/sdm/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewer/sdm/","section":"reviewer","summary":"Conference","tags":[],"title":"SIAM International Conference on Data Mining (SDM-22)","type":"reviewer"}]